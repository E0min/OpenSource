{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash\n",
    "!pip install gensim\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('../kr3.tsv', sep='\\t')\n",
    "\n",
    "# 긍정 리뷰와 부정 리뷰 필터링 및 결측값 제거\n",
    "print(\"데이터 필터링 및 전처리...\")\n",
    "positive_reviews = df[df['Rating'] == 1]['Review'].dropna()\n",
    "negative_reviews = df[df['Rating'] == 0]['Review'].dropna()\n",
    "\n",
    "# Okt 토크나이저로 토큰화\n",
    "print(\"토큰화 진행 중...\")\n",
    "okt = Okt()\n",
    "tokenized_pos_reviews = [okt.morphs(review) for review in tqdm(positive_reviews)]\n",
    "tokenized_neg_reviews = [okt.morphs(review) for review in tqdm(negative_reviews)]\n",
    "\n",
    "# Word2Vec 모델 훈련\n",
    "print(\"Word2Vec 모델 훈련 중...\")\n",
    "model_w2v = Word2Vec(sentences=tokenized_pos_reviews + tokenized_neg_reviews, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# 리뷰당 평균 Word2Vec 벡터 계산 함수\n",
    "def document_vector(word2vec_model, doc):\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.index_to_key]\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0) if len(doc) > 0 else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# 긍정 리뷰와 부정 리뷰에 대한 평균 벡터 계산\n",
    "print(\"리뷰 벡터 계산 중...\")\n",
    "doc_vectors_pos = np.array([document_vector(model_w2v, doc) for doc in tqdm(tokenized_pos_reviews) if len(doc) > 0])\n",
    "doc_vectors_neg = np.array([document_vector(model_w2v, doc) for doc in tqdm(tokenized_neg_reviews) if len(doc) > 0])\n",
    "\n",
    "# K-means 클러스터링 적용\n",
    "print(\"K-means 클러스터링 진행 중...\")\n",
    "num_clusters = 10\n",
    "kmeans_pos = KMeans(n_clusters=num_clusters, random_state=42).fit(doc_vectors_pos)\n",
    "kmeans_neg = KMeans(n_clusters=num_clusters, random_state=42).fit(doc_vectors_neg)\n",
    "\n",
    "# 결과 저장 및 출력\n",
    "print(\"결과 저장 및 출력 중...\")\n",
    "joblib.dump(kmeans_pos, './kmeans_pos_model.pkl')\n",
    "joblib.dump(kmeans_neg, './kmeans_neg_model.pkl')\n",
    "\n",
    "# 클러스터 중심에 가장 가까운 단어들을 찾는 함수\n",
    "def closest_words(word2vec_model, centroid, n=10):\n",
    "    all_words = word2vec_model.wv.index_to_key\n",
    "    centroid_vector = centroid\n",
    "    distances = [np.linalg.norm(word2vec_model.wv[word] - centroid_vector) for word in all_words]\n",
    "    sorted_distances = sorted(zip(all_words, distances), key=lambda x: x[1])\n",
    "    return [word for word, dist in sorted_distances[:n]]\n",
    "\n",
    "# 긍정 리뷰 클러스터 결과와 클러스터 중심에 가장 가까운 단어 출력\n",
    "print(\"긍정 리뷰 클러스터 결과:\")\n",
    "for i in range(num_clusters):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    words_closest_to_centroid = closest_words(model_w2v, kmeans_pos.cluster_centers_[i])\n",
    "    print(f\"가까운 단어들: {', '.join(words_closest_to_centroid)}\")\n",
    "    cluster_indices = np.where(kmeans_pos.labels_ == i)[0]\n",
    "    for idx in cluster_indices[:10]:\n",
    "        print(positive_reviews.iloc[idx])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 부정 리뷰 클러스터 결과와 클러스터 중심에 가장 가까운 단어 출력\n",
    "print(\"부정 리뷰 클러스터 결과:\")\n",
    "for i in range(num_clusters):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    words_closest_to_centroid = closest_words(model_w2v, kmeans_neg.cluster_centers_[i])\n",
    "    print(f\"가까운 단어들: {', '.join(words_closest_to_centroid)}\")\n",
    "    cluster_indices = np.where(kmeans_neg.labels_ == i)[0]\n",
    "    for idx in cluster_indices[:10]:\n",
    "        print(negative_reviews.iloc[idx])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
